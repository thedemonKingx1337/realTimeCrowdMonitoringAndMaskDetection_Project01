{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import gc\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from glob import glob  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = os.listdir('Dataset')\n",
    "images_path = []                 #[]empty list\n",
    "labels = []                      #[]empty list\n",
    "for folder in dirs:\n",
    "    #folder = 'Mask'             #checkstatment\n",
    "    path = glob('./Dataset/{}/*.jpg'.format(folder))\n",
    "    label = ['{}'.format(folder)]*len(path)\n",
    "    #print(dirs)\n",
    "    \n",
    "    #appending\n",
    "    images_path.extend(path)\n",
    "    labels.extend(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(label)                      #Checkstatment\n",
    "img_path = images_path[1]\n",
    "img = cv2.imread(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('original',img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading face detection models\n",
    "face_detection_model = cv2.dnn.readNetFromCaffe('./models/deploy.prototxt.txt', './models/res10_300x300_ssd_iter_140000_fp16.caffemodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detection_dnn(img):\n",
    "    # calculating blob from image (RGB mean subtraction from image)\n",
    "    image = img.copy()\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(image,1,(300, 300),(104, 117, 123), swapRB=True)     # (image[,scalefactor[,sizw[,mean[,swapRB,crop[,depth]]]]]\n",
    "\n",
    "    # getting detections  passing blob as input to face_detection_model         \n",
    "    face_detection_model.setInput(blob)\n",
    "    detections = face_detection_model.forward()\n",
    "    #print(detections)\n",
    "    for i in range(0,detections.shape[2]):\n",
    "        confidence = detections[0,0,i,2]    #confidence score\n",
    "        #print(confidence)                  #checkstatment\n",
    "        if confidence > 0.5:\n",
    "            #print(confidence)\n",
    "            box = detections[0,0,i,3:7]*np.array([w,h,w,h])       #detections[0,0,i,3:7] give you bounding box info but in normalized form to de normalize * np.array([w,h,w,h]) multiply with W & H\n",
    "            box = box.astype(int)\n",
    "            #print(box)         #checkstatment      \n",
    "            pt1 = (box[0],box[1])        #diagonal point of bounding box\n",
    "            pt2 = (box[2],box[3])        #diagonal point of bounding box\n",
    "            #cv2.rectangle(image,pt1,pt2,(0,255,0),2)       #colour,thickness_values     #checkstatment\n",
    "            roi = image[box[1]:box[3],box[0]:box[2]]\n",
    "\n",
    "            return roi \n",
    "    return None        \n",
    "\n",
    "    #cv2.imshow('detected face',image)               #checkstatment\n",
    "    #cv2.imshow('roi',roi)                           #checkstatment\n",
    "    #cv2.waitKey(0)                                  #checkstatment\n",
    "    #cv2.destroyAllWindows()                         #checkstatment      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detections.shape            #checkstatment\n",
    "img_roi = face_detection_dnn(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('roi',img_roi)\n",
    "cv2.imshow('original',img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapreprocess(img):\n",
    "    #blob from image(RGB mean subtraction from image)\n",
    "    face = face_detection_dnn(img)\n",
    "    if face is not None:      #all values will not be roi some will be none \n",
    "        #computing blob from image \n",
    "        blob = cv2.dnn.blobFromImage(face,1,(100,100),(104,117,123),swapRB=True)  #(image[,scalefactor[,sizw[,mean[,swapRB,crop[,depth]]]]]])   #if face any mem error reduce 100,100 to 80,80\n",
    "        #print(blob.shape) #o/p: returing was on 4D so we need to squeeze to 3D   #checkstatment\n",
    "        blob_squeeze = np.squeeze(blob).T  \n",
    "        #print(blob_squeeze.shape)  #o/p is in 3D #checkstatment   \n",
    "        blob_rotate = cv2.rotate(blob_squeeze,cv2.ROTATE_90_CLOCKWISE)\n",
    "        \n",
    "        blob_flip = cv2.flip(blob_rotate,1)\n",
    "\n",
    "        #removing the negative values and normalizing the values\n",
    "        img_norm = np.maximum(blob_flip,0)/blob_flip.max()      #0is the cutoff value.values below 0 are set to 0\n",
    "\n",
    "        return img_norm\n",
    "    else:\n",
    "        return None    \n",
    "\n",
    "\n",
    "    #cv2.imshow('roi',face)                                                     #checkstatment\n",
    "    #cv2.namedWindow('blob',cv2.WINDOW_NORMAL)  #for_resizeing_blob_window      #checkstatment\n",
    "    #cv2.namedWindow('blob_rotate',cv2.WINDOW_NORMAL)\n",
    "    #cv2.namedWindow('blob_flip',cv2.WINDOW_NORMAL)                             #checkstatment\n",
    "    #cv2.imshow('blob',blob_squeeze)                                            #checkstatment\n",
    "    #cv2.imshow('blob_rotate',blob_rotate)\n",
    "    #cv2.imshow('blob_flip',blob_flip)\n",
    "    #cv2.waitKey()\n",
    "    #cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preprocessing: 134782it [2:41:55, 13.87it/s]\n"
     ]
    }
   ],
   "source": [
    "#applying to all images\n",
    "#len(images_path)       #checkstatment\n",
    "\n",
    "data_img = []\n",
    "labels_img = []\n",
    "i = 0\n",
    "for path,label in tqdm(zip(images_path,labels),desc='preprocessing'):  #to_know_eq_seq_No:_we_use tqdm\n",
    "    img = cv2.imread(path)\n",
    "    process_img = datapreprocess(img)\n",
    "    if process_img is not None:\n",
    "        data_img.append(process_img)\n",
    "        labels_img.append(label)\n",
    "    i += 1    #i=i+1    \n",
    "    if i%100 == 0:\n",
    "        gc.collect()                                                  #approx_time 170min 30.2sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blob_flip.max() , blob_flip.min()                      #there must not be negative value\n",
    "x = np.array(data_img)\n",
    "y = np.array(labels_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((134097, 100, 100, 3), (134097,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('./Dataset/data_preprocess.npz',x,y)               #approx time 21min23sec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "18eec52fc56095477986479c382d68a0f1470788a37d50d8c146bb4f9cf6515d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
